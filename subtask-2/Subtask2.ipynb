{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Subtask1",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **Subtask 2**: Semantic type of premise classification\n",
    "\n",
    "This Notebook contains all the code that was used for the task of semantic type of premise identification\n",
    "\n",
    "Please note that currently this notebook is setup to obtain results on our own annotated test set for this task. This means that the variable <i>original_annotations</i> is set to <b>False</b>\n",
    "\n",
    "Other prompt templates that we experimented with can be found in the <i>prompt templates</i> notebook"
   ],
   "metadata": {
    "id": "ZU1Pc9ne4oB4",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l3f8-OqVS9D-",
    "outputId": "2ec6d9f1-421f-479a-fe95-f2962d1071b0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.5.18.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fv32aFfySP6s",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# Use our own annotations and initialize GPT-NEO model and tokenizer\n",
    "original_annotations = False\n",
    "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Validation set that was used for prompt template engineering\n",
    "val_sents = [\"Another reason for my opinion is that CoD doesn't really have anything astoundingly different from other games of the same genre.\",\n",
    "             \"So why would a bunch of social outcasts who get made fun of encourage hate and let such raw emotion reign supreme?\",\n",
    "             \"a large part of this view came from something a history teacher told me 6 years ago: \\\"Geography Determines Destiny\\\", and that quote has stuck with me\",\n",
    "             \"I am an omnivore, and my diet consists of meat and plants.\",\n",
    "             \"Saying these people shouldnâ€™t be allowed to become part of the country, is the same as saying they are worse,\",\n",
    "             \"Every middle-class child in the country would receive a lower quality education if there were 55 million more around\",\n",
    "             \"Why do I feel like chasing after girls and getting to know them when I have so many great guy friends already who I know care about me so much more?\",\n",
    "             \"you'll still probably feel attraction for other people\",\n",
    "             \"their chances of getting shot would also increase\"]\n",
    "\n",
    "val_types = ['Ethos',\n",
    "             'Pathos',\n",
    "             'Ethos',\n",
    "             'Ethos',\n",
    "             'Pathos',\n",
    "             'Logos',\n",
    "             'Logos',\n",
    "             'Pathos',\n",
    "             'Logos']\n",
    "\n",
    "val_tuples = list(zip(val_sents, val_types))\n",
    "df_val = pd.DataFrame(val_tuples, columns=['Premise','Type']) "
   ],
   "metadata": {
    "id": "_LerAjXf2aDO",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Initialize test set\n",
    "df = pd.read_csv('../data/subtask-2/gold_test.csv', index_col=0)"
   ],
   "metadata": {
    "id": "ChJwpSHtWh0S",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# GPT-NEO to fill out the prompt\n",
    "neo_predictions = []\n",
    "for premise in df['premise'].to_list():\n",
    "    if original_annotations:\n",
    "        print('moi')\n",
    "        prompt = (f\"\"\"Premise: Therefore, there will always be a market for meat and other animal products\n",
    "            Type: logos_pathos\n",
    "            ###\n",
    "            Premise: How often do we get to go back and correct our mistakes in real life, anyway?\n",
    "            Type: logos_pathos\n",
    "            ###\n",
    "            Premise: I'l begin by saying it has never happened to me\n",
    "            Type: ethos\n",
    "            ###\n",
    "            Premise: Individuals who are extraordinarily qualified for a position but come from a region/social background without those connections enter a networking-friendly employment opportunity at a disadvantage.\n",
    "            Type: logos_pathos\n",
    "            ###\n",
    "            Premise: I'm an immigrant and a Muslim neither of which is or should be a deterrent from joining\n",
    "            Type: ethos\n",
    "            ###\n",
    "            Premise: how many of these women wouldn't be having financial troubles if there wasn't competition from cheap illegal labor to keep wages lower\n",
    "            Type: logos_pathos\n",
    "            ###\n",
    "            Premise: {premise}\n",
    "            Type:\"\"\"\n",
    "        )\n",
    "    else:\n",
    "        print('here')\n",
    "        # 1. Logos, 2. Pathos, 3. Ethos\n",
    "        prompt = (f\"\"\"Premise: How often do we get to go back and correct our mistakes in real life, anyway?\n",
    "            Type: 2\n",
    "            ###\n",
    "            Premise: Therefore, there will always be a market for meat and other animal products\n",
    "            Type: 1\n",
    "            ###\n",
    "            Premise: I'l begin by saying it has never happened to me\n",
    "            Type: 3\n",
    "            ###\n",
    "            Premise: Individuals who are extraordinarily qualified for a position but come from a region/social background without those connections enter a networking-friendly employment opportunity at a disadvantage.\n",
    "            Type: 1\n",
    "            ###\n",
    "            Premise: I'm an immigrant and a Muslim neither of which is or should be a deterrent from joining\n",
    "            Type: 3\n",
    "            ###\n",
    "            Premise: how many of these women wouldn't be having financial troubles if there wasn't competition from cheap illegal labor to keep wages lower\n",
    "            Type: 2\n",
    "            ###\n",
    "            Premise: {premise}\n",
    "            Type:\"\"\"\n",
    "        )\n",
    "\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    gen_tokens = model.generate(\n",
    "        input_ids,\n",
    "        temperature=0.8,\n",
    "        min_length=1,\n",
    "        length_no_input=True,\n",
    "        end_sequence='\\n###',\n",
    "        remove_end_sequence=True,\n",
    "        remove_input=True\n",
    "    )\n",
    "\n",
    "    gen_text = tokenizer.batch_decode(gen_tokens)[0]\n",
    "    # Remove input prompt from the output\n",
    "    strs = gen_text.replace(prompt,\"\")\n",
    "    neo_predictions.append(strs.strip())\n",
    "\n",
    "if original_annotations:\n",
    "    df['neo_pred_original'] = neo_predictions\n",
    "else:\n",
    "    df['neo_pred'] = neo_predictions"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y0zF14z-S3zu",
    "outputId": "78051828-87dd-4733-fc01-319ba7f0371b",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 425, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 431, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 414, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 429, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 410, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 413, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 420, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 441, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 403, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 408, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 405, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 424, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 438, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 427, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 406, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 406, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 432, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 415, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 420, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 405, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 400, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 432, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 404, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 410, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 397, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 398, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 409, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 404, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 408, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 429, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 401, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 418, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 421, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 410, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 412, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 443, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 415, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 405, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 402, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 407, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 400, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 442, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 406, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 411, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 405, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 432, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 422, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 407, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 419, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 416, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 416, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 423, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 422, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 406, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 437, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 399, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 414, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 409, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 405, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 416, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 412, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 403, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 408, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 400, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 407, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 410, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 403, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 424, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 412, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 418, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 419, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 417, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 395, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 400, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 415, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 410, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 400, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 424, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 406, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 428, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 399, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 395, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Input length of input_ids is 405, but ``max_length`` is set to 20. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n",
      "here\n",
      "1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "M8AJP1tLMCfS",
    "outputId": "e0c5befa-6a8a-4c0b-9f38-08f676170dc0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    Unnamed: 0.1  document              file_path     split  \\\n",
       "66           101        21   v2.0/positive/21.xml  positive   \n",
       "18            23        21   v2.0/positive/21.xml  positive   \n",
       "42            65        79   v2.0/negative/79.xml  negative   \n",
       "67           102        19   v2.0/positive/19.xml  positive   \n",
       "55            84        94   v2.0/negative/94.xml  negative   \n",
       "..           ...       ...                    ...       ...   \n",
       "76           117       248  v2.0/negative/248.xml  negative   \n",
       "84           128        79   v2.0/positive/79.xml  positive   \n",
       "9             12        95   v2.0/positive/95.xml  positive   \n",
       "11            14        18   v2.0/positive/18.xml  positive   \n",
       "1              3        76   v2.0/positive/76.xml  positive   \n",
       "\n",
       "                                              premise    gold our_type  \\\n",
       "66   I know that the chocolates I love to eat cont...   logos    logos   \n",
       "18   which you see frequently among people in empa...   ethos    ethos   \n",
       "42  An aborted fetus is likely to have been a less...   logos    logos   \n",
       "67  As for the â€œTheyâ€™re not risking their lives fo...   logos   pathos   \n",
       "55  As if creating jobs for americans is morally s...  pathos   pathos   \n",
       "..                                                ...     ...      ...   \n",
       "76  other than anecdotal evidence, I haven't seen ...   logos    logos   \n",
       "84  the man tries to show the woman how non-threat...   logos    logos   \n",
       "9               their will always be a few bad apples   logos    logos   \n",
       "11                              there is no afterlife   logos       ??   \n",
       "1   when this system scales up you need to include...   logos    logos   \n",
       "\n",
       "   Unnamed: 7          type neo_pred neo_pred_keep  \n",
       "66      logos  logos_pathos        1             1  \n",
       "18      ethos  logos_pathos        1             1  \n",
       "42      logos  logos_pathos        1             1  \n",
       "67      logos  logos_pathos        1             1  \n",
       "55     pathos  logos_pathos        1             1  \n",
       "..        ...           ...      ...           ...  \n",
       "76      logos  logos_pathos        1             1  \n",
       "84      logos  logos_pathos        1             1  \n",
       "9       logos  logos_pathos        1             1  \n",
       "11          x  logos_pathos        1             1  \n",
       "1       logos  logos_pathos        1             1  \n",
       "\n",
       "[83 rows x 11 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-2b05a35d-c176-406b-b741-44506d33cd96\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>document</th>\n",
       "      <th>file_path</th>\n",
       "      <th>split</th>\n",
       "      <th>premise</th>\n",
       "      <th>gold</th>\n",
       "      <th>our_type</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>type</th>\n",
       "      <th>neo_pred</th>\n",
       "      <th>neo_pred_keep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>101</td>\n",
       "      <td>21</td>\n",
       "      <td>v2.0/positive/21.xml</td>\n",
       "      <td>positive</td>\n",
       "      <td>I know that the chocolates I love to eat cont...</td>\n",
       "      <td>logos</td>\n",
       "      <td>logos</td>\n",
       "      <td>logos</td>\n",
       "      <td>logos_pathos</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>23</td>\n",
       "      <td>21</td>\n",
       "      <td>v2.0/positive/21.xml</td>\n",
       "      <td>positive</td>\n",
       "      <td>which you see frequently among people in empa...</td>\n",
       "      <td>ethos</td>\n",
       "      <td>ethos</td>\n",
       "      <td>ethos</td>\n",
       "      <td>logos_pathos</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>65</td>\n",
       "      <td>79</td>\n",
       "      <td>v2.0/negative/79.xml</td>\n",
       "      <td>negative</td>\n",
       "      <td>An aborted fetus is likely to have been a less...</td>\n",
       "      <td>logos</td>\n",
       "      <td>logos</td>\n",
       "      <td>logos</td>\n",
       "      <td>logos_pathos</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>102</td>\n",
       "      <td>19</td>\n",
       "      <td>v2.0/positive/19.xml</td>\n",
       "      <td>positive</td>\n",
       "      <td>As for the â€œTheyâ€™re not risking their lives fo...</td>\n",
       "      <td>logos</td>\n",
       "      <td>pathos</td>\n",
       "      <td>logos</td>\n",
       "      <td>logos_pathos</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>84</td>\n",
       "      <td>94</td>\n",
       "      <td>v2.0/negative/94.xml</td>\n",
       "      <td>negative</td>\n",
       "      <td>As if creating jobs for americans is morally s...</td>\n",
       "      <td>pathos</td>\n",
       "      <td>pathos</td>\n",
       "      <td>pathos</td>\n",
       "      <td>logos_pathos</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>117</td>\n",
       "      <td>248</td>\n",
       "      <td>v2.0/negative/248.xml</td>\n",
       "      <td>negative</td>\n",
       "      <td>other than anecdotal evidence, I haven't seen ...</td>\n",
       "      <td>logos</td>\n",
       "      <td>logos</td>\n",
       "      <td>logos</td>\n",
       "      <td>logos_pathos</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>128</td>\n",
       "      <td>79</td>\n",
       "      <td>v2.0/positive/79.xml</td>\n",
       "      <td>positive</td>\n",
       "      <td>the man tries to show the woman how non-threat...</td>\n",
       "      <td>logos</td>\n",
       "      <td>logos</td>\n",
       "      <td>logos</td>\n",
       "      <td>logos_pathos</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>95</td>\n",
       "      <td>v2.0/positive/95.xml</td>\n",
       "      <td>positive</td>\n",
       "      <td>their will always be a few bad apples</td>\n",
       "      <td>logos</td>\n",
       "      <td>logos</td>\n",
       "      <td>logos</td>\n",
       "      <td>logos_pathos</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>v2.0/positive/18.xml</td>\n",
       "      <td>positive</td>\n",
       "      <td>there is no afterlife</td>\n",
       "      <td>logos</td>\n",
       "      <td>??</td>\n",
       "      <td>x</td>\n",
       "      <td>logos_pathos</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "      <td>v2.0/positive/76.xml</td>\n",
       "      <td>positive</td>\n",
       "      <td>when this system scales up you need to include...</td>\n",
       "      <td>logos</td>\n",
       "      <td>logos</td>\n",
       "      <td>logos</td>\n",
       "      <td>logos_pathos</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83 rows Ã— 11 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b05a35d-c176-406b-b741-44506d33cd96')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-2b05a35d-c176-406b-b741-44506d33cd96 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-2b05a35d-c176-406b-b741-44506d33cd96');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df['neo_pred_keep'] = df['neo_pred']"
   ],
   "metadata": {
    "id": "21Fuvq7NSgAl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Report on gold labels and predictions, showing classification report and\n",
    "# confusion matrix\n",
    "def report(y_true, y_pred):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True)\n",
    "    df_report = pd.DataFrame.from_dict(report).transpose().round({'precision': 2, 'recall': 2, 'f1-score': 2, 'support': 0})\n",
    "    print(df_report.to_latex())\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred)\n",
    "\n",
    "# ORIGINAL ANNOTATIONS\n",
    "if original_annotations:\n",
    "    df['neo_pred_original'].replace({'logos': 'logos_pathos', 'pathos': 'logos_pathos'}, inplace=True)\n",
    "    y_true = df['type'].to_list()\n",
    "    y_pred = df['neo_pred_original'].to_list()\n",
    "    report(y_true, y_pred)\n",
    "\n",
    "# OUR ANNOTATIONS\n",
    "else:\n",
    "    repl_dict = {'1': 'logos', '2': 'pathos', '3': 'ethos'}\n",
    "    df['neo_pred'] = df['neo_pred'].map(repl_dict)\n",
    "    y_true = df['gold'].to_list()\n",
    "    y_pred = df['neo_pred'].to_list()\n",
    "    report(y_true, y_pred)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "id": "7-U-iu2SVIUN",
    "outputId": "3c2c900b-1acd-45ea-c4c7-3c9862d94105",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "{} &  precision &  recall &  f1-score &  support \\\\\n",
      "\\midrule\n",
      "ethos        &       0.00 &    0.00 &      0.00 &     23.0 \\\\\n",
      "logos        &       0.49 &    1.00 &      0.66 &     41.0 \\\\\n",
      "pathos       &       0.00 &    0.00 &      0.00 &     19.0 \\\\\n",
      "accuracy     &       0.49 &    0.49 &      0.49 &      0.0 \\\\\n",
      "macro avg    &       0.16 &    0.33 &      0.22 &     83.0 \\\\\n",
      "weighted avg &       0.24 &    0.49 &      0.33 &     83.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "6Kgp5fQvL-FB",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}